{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ip3NVwCJ1-0s",
        "jd6Oi0Z15rxR",
        "t82cQeF5_LUZ",
        "DjwEXljOBHyQ",
        "5BgPJWWIBrQ0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 1**\n",
        "All Features"
      ],
      "metadata": {
        "id": "HMKAu_zrvO9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adding Image Type Dummy Variables**"
      ],
      "metadata": {
        "id": "_YkKe5yezYfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your original DataFrame\n",
        "# Let's consider 'Image Type' for illustration\n",
        "df = pd.read_csv('All_')\n",
        "# Step 1: Create a copy of the DataFrame to avoid modifying the original\n",
        "df_encoded = df.copy()\n",
        "\n",
        "# Step 2: Create dummy variables for 'Image Type'\n",
        "image_type_dummies = pd.get_dummies(df_encoded['Image Type'], prefix='ImageType')\n",
        "\n",
        "# Step 3: Concatenate the dummy variables with the original DataFrame\n",
        "df_encoded = pd.concat([df_encoded, image_type_dummies], axis=1)\n",
        "\n",
        "# Step 4: Drop the original 'Image Type' column\n",
        "df_encoded = df_encoded.drop('Image Type', axis=1)\n",
        "\n",
        "# Step 5: Rename the dummy columns with custom names\n",
        "df_encoded = df_encoded.rename(columns={'ImageType_1': 'AI Image', 'ImageType_0': 'Human Image', 'ImageType_-1': 'No Image'})\n",
        "\n",
        "# Step 2: Create dummy variables for 'Topic'\n",
        "image_type_dummies = pd.get_dummies(df_encoded['Topic'])\n",
        "\n",
        "# Step 3: Concatenate the dummy variables with the original DataFrame\n",
        "df_encoded = pd.concat([df_encoded, image_type_dummies], axis=1)\n",
        "\n",
        "# Step 4: Drop the original 'Topic' column\n",
        "df_encoded = df_encoded.drop('Topic', axis=1)\n",
        "\n",
        "# Step 2: Create dummy variables for 'Text Sentiment'\n",
        "image_type_dummies = pd.get_dummies(df_encoded['Text Sentiment'])\n",
        "\n",
        "# Step 3: Concatenate the dummy variables with the original DataFrame\n",
        "df_encoded = pd.concat([df_encoded, image_type_dummies], axis=1)\n",
        "\n",
        "# Step 4: Drop the original 'Text Sentiment' column\n",
        "df_encoded = df_encoded.drop('Text Sentiment', axis=1)\n",
        "\n",
        "# Step 5: Rename the dummy columns with custom names\n",
        "df_encoded = df_encoded.rename(columns={-1: 'Negative Sentiment', 0: 'Neutral Sentiment', 1: 'Positive Sentiment'})\n",
        "\n",
        "# Step 2: Create dummy variables for 'Quality of Image'\n",
        "image_type_dummies = pd.get_dummies(df_encoded['Quality of Image'])\n",
        "\n",
        "# Step 3: Concatenate the dummy variables with the original DataFrame\n",
        "df_encoded = pd.concat([df_encoded, image_type_dummies], axis=1)\n",
        "\n",
        "# Step 4: Drop the original 'Quality of Image' column\n",
        "df_encoded = df_encoded.drop('Quality of Image', axis=1)\n",
        "\n",
        "# Step 5: Rename the dummy columns with custom names\n",
        "df_encoded = df_encoded.rename(columns={-1: 'Low Quality Image', 0: 'None', 1: 'High Quality Image'})\n",
        "df_encoded = df_encoded.drop('None', axis=1)\n",
        "\n",
        "# Step 2: Create dummy variables for 'Relevant Image'\n",
        "image_type_dummies = pd.get_dummies(df_encoded['Relevant Image'])\n",
        "\n",
        "# Step 3: Concatenate the dummy variables with the original DataFrame\n",
        "df_encoded = pd.concat([df_encoded, image_type_dummies], axis=1)\n",
        "\n",
        "# Step 4: Drop the original 'Relevant Image' column\n",
        "df_encoded = df_encoded.drop('Relevant Image', axis=1)\n",
        "\n",
        "# Step 5: Rename the dummy columns with custom names\n",
        "df_encoded = df_encoded.rename(columns={-1: 'Irrelevant Image', 0: 'None', 1: 'Relevant Image'})\n",
        "df_encoded = df_encoded.drop('None', axis=1)\n",
        "\n",
        "# Step 2: Create dummy variables for 'Face Presence'\n",
        "image_type_dummies = pd.get_dummies(df_encoded['Face Presence'])\n",
        "\n",
        "# Step 3: Concatenate the dummy variables with the original DataFrame\n",
        "df_encoded = pd.concat([df_encoded, image_type_dummies], axis=1)\n",
        "\n",
        "# Step 4: Drop the original 'Face Presence' column\n",
        "df_encoded = df_encoded.drop('Face Presence', axis=1)\n",
        "\n",
        "# Step 5: Rename the dummy columns with custom names\n",
        "df_encoded = df_encoded.rename(columns={-1: 'No Face Present', 0: 'None', 1: 'Face Present'})\n",
        "df_encoded = df_encoded.drop('None', axis=1)\n",
        "\n",
        "# Extract month and hour from the timestamp\n",
        "df_encoded['Timestamp'] = pd.to_datetime(df_encoded['Timestamp'])\n",
        "df_encoded['Month'] = df_encoded['Timestamp'].dt.month\n",
        "df_encoded['Hour'] = df_encoded['Timestamp'].dt.hour\n",
        "df_encoded = df_encoded.drop('Timestamp', axis=1)\n",
        "\n",
        "# Step 2: Create dummy variables for 'Month'\n",
        "image_type_dummies = pd.get_dummies(df_encoded['Month'])\n",
        "\n",
        "# Step 3: Concatenate the dummy variables with the original DataFrame\n",
        "df_encoded = pd.concat([df_encoded, image_type_dummies], axis=1)\n",
        "\n",
        "# Step 4: Drop the original 'Month' column\n",
        "df_encoded = df_encoded.drop('Month', axis=1)\n",
        "\n",
        "# Step 5: Rename the dummy columns with custom names\n",
        "df_encoded = df_encoded.rename(columns={1: 'January', 2: 'February', 3: 'March', 4: 'April', 5:'May', 6:'June', 7:'July', 8:'August', 9:'September', 10:'October', 11:'November', 12:'December'})\n",
        "\n",
        "# Step 2: Create dummy variables for 'Hour'\n",
        "image_type_dummies = pd.get_dummies(df_encoded['Hour'], prefix='Hour')\n",
        "\n",
        "# Step 3: Concatenate the dummy variables with the original DataFrame\n",
        "df_encoded = pd.concat([df_encoded, image_type_dummies], axis=1)\n",
        "\n",
        "# Step 4: Drop the original 'Hour' column\n",
        "df_encoded = df_encoded.drop('Hour', axis=1)\n",
        "\n",
        "# drop the text and image columns because you don't need them for your data\n",
        "df_encoded = df_encoded.drop('Text', axis=1)\n",
        "df_encoded = df_encoded.drop('Images', axis=1)\n",
        "# Display the resulting DataFrame\n",
        "display(df_encoded.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "PglYAidjwBQE",
        "outputId": "17f9f30e-2e9b-4266-a514-93d31678d4ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Engagement Score  Word Count  Number of Hashtags  Colorfulness  No Image  \\\n",
              "0             10.53          16                   5      7.840725         0   \n",
              "1             10.34          17                   4     11.375263         0   \n",
              "2             10.08           2                   9     11.805964         0   \n",
              "3             10.00           3                   7     10.789090         0   \n",
              "4              9.38           5                  19      0.000000         0   \n",
              "\n",
              "   Human Image  AI Image  AI art  Art Commission  Digital art  ...  Hour_14  \\\n",
              "0            1         0       0               0            0  ...        1   \n",
              "1            1         0       0               1            0  ...        0   \n",
              "2            0         1       1               0            0  ...        0   \n",
              "3            1         0       0               0            1  ...        0   \n",
              "4            1         0       0               0            1  ...        0   \n",
              "\n",
              "   Hour_15  Hour_16  Hour_17  Hour_18  Hour_19  Hour_20  Hour_21  Hour_22  \\\n",
              "0        0        0        0        0        0        0        0        0   \n",
              "1        0        0        0        0        0        0        0        0   \n",
              "2        0        0        0        0        0        0        0        0   \n",
              "3        0        0        0        0        0        0        0        0   \n",
              "4        0        0        1        0        0        0        0        0   \n",
              "\n",
              "   Hour_23  \n",
              "0        0  \n",
              "1        0  \n",
              "2        0  \n",
              "3        0  \n",
              "4        0  \n",
              "\n",
              "[5 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf0f3de5-d2fb-4d20-9488-7699596cb12d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Engagement Score</th>\n",
              "      <th>Word Count</th>\n",
              "      <th>Number of Hashtags</th>\n",
              "      <th>Colorfulness</th>\n",
              "      <th>No Image</th>\n",
              "      <th>Human Image</th>\n",
              "      <th>AI Image</th>\n",
              "      <th>AI art</th>\n",
              "      <th>Art Commission</th>\n",
              "      <th>Digital art</th>\n",
              "      <th>...</th>\n",
              "      <th>Hour_14</th>\n",
              "      <th>Hour_15</th>\n",
              "      <th>Hour_16</th>\n",
              "      <th>Hour_17</th>\n",
              "      <th>Hour_18</th>\n",
              "      <th>Hour_19</th>\n",
              "      <th>Hour_20</th>\n",
              "      <th>Hour_21</th>\n",
              "      <th>Hour_22</th>\n",
              "      <th>Hour_23</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.53</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>7.840725</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.34</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>11.375263</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.08</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>11.805964</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.00</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>10.789090</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.38</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 62 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf0f3de5-d2fb-4d20-9488-7699596cb12d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf0f3de5-d2fb-4d20-9488-7699596cb12d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf0f3de5-d2fb-4d20-9488-7699596cb12d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-945781c2-8c64-460b-a32b-e8bee463103a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-945781c2-8c64-460b-a32b-e8bee463103a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-945781c2-8c64-460b-a32b-e8bee463103a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pRWM4n5IECPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Load your dataset (replace 'All_Tweets_Transformed-Final.csv' with your actual file path)\n",
        "df = df_encoded\n",
        "\n",
        "# Drop rows with NaN values in the target variable\n",
        "df_regression = df.dropna(subset=['Engagement Score'])\n",
        "\n",
        "# Exclude 'Engagement Score' from the features matrix\n",
        "X = df_regression.drop('Engagement Score', axis=1)  # Exclude the target variable\n",
        "X = sm.add_constant(X)  # Add a constant term to the features matrix\n",
        "\n",
        "# Target variable\n",
        "y = df_regression['Engagement Score']\n",
        "\n",
        "# Take a random sample of 700\n",
        "df_sample = resample(df_regression, n_samples=700, random_state=42)\n",
        "\n",
        "# Separate features and target variable for the sample\n",
        "X_sample = df_sample.drop('Engagement Score', axis=1)\n",
        "X_sample = sm.add_constant(X_sample)\n",
        "y_sample = df_sample['Engagement Score']\n",
        "\n",
        "# Split the data into training and testing sets for the sample\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Add a constant term to the features matrix\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "# Fit a Negative Binomial regression model\n",
        "neg_binomial_model = sm.GLM(y_train, X_train_scaled, family=sm.families.NegativeBinomial()).fit()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = neg_binomial_model.predict(X_test_scaled)\n",
        "\n",
        "# Display the summary of the model\n",
        "print(neg_binomial_model.summary())\n",
        "\n",
        "# Calculate AIC and BIC\n",
        "aic = neg_binomial_model.aic\n",
        "bic = neg_binomial_model.bic\n",
        "\n",
        "print(f'AIC: {aic}')\n",
        "print(f'BIC: {bic}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6ZHAWy3vNcr",
        "outputId": "28c16fe6-e49a-4524-8860-43d8d9865736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1402: RuntimeWarning: invalid value encountered in divide\n",
            "  endog_mu = self._clean(endog / mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:       Engagement Score   No. Observations:                  560\n",
            "Model:                            GLM   Df Residuals:                      503\n",
            "Model Family:        NegativeBinomial   Df Model:                           56\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -1103.9\n",
            "Date:                Tue, 28 Nov 2023   Deviance:                       362.57\n",
            "Time:                        22:04:23   Pearson chi2:                     309.\n",
            "No. Iterations:                   100   Pseudo R-squ. (CS):             0.1604\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       1.028e-12   7.06e-14     14.558      0.000     8.9e-13    1.17e-12\n",
            "x1            -0.1504      0.066     -2.270      0.023      -0.280      -0.021\n",
            "x2            -0.1245      0.085     -1.473      0.141      -0.290       0.041\n",
            "x3             0.0373      0.068      0.547      0.585      -0.096       0.171\n",
            "x4            -0.0138      0.696     -0.020      0.984      -1.378       1.350\n",
            "x5             0.2256      0.247      0.911      0.362      -0.259       0.711\n",
            "x6            -0.2285      0.249     -0.918      0.359      -0.716       0.259\n",
            "x7             1.5072      0.381      3.954      0.000       0.760       2.254\n",
            "x8             0.5281      0.153      3.459      0.001       0.229       0.827\n",
            "x9             0.8161      0.301      2.712      0.007       0.226       1.406\n",
            "x10            0.4085      0.121      3.381      0.001       0.172       0.645\n",
            "x11            0.3900      0.156      2.501      0.012       0.084       0.696\n",
            "x12            0.5732      0.199      2.874      0.004       0.182       0.964\n",
            "x13            0.7116      0.239      2.975      0.003       0.243       1.181\n",
            "x14            0.7482      0.299      2.505      0.012       0.163       1.334\n",
            "x15            0.4282      0.163      2.631      0.009       0.109       0.747\n",
            "x16            0.2208      0.101      2.190      0.029       0.023       0.418\n",
            "x17            0.3235      0.157      2.063      0.039       0.016       0.631\n",
            "x18            0.0060      0.049      0.121      0.903      -0.090       0.102\n",
            "x19           -0.0297      0.032     -0.915      0.360      -0.093       0.034\n",
            "x20            0.0288      0.035      0.834      0.405      -0.039       0.097\n",
            "x21          143.3129      9.787     14.643      0.000     124.130     162.496\n",
            "x22          184.9734     12.625     14.651      0.000     160.228     209.719\n",
            "x23         -151.2388     10.471    -14.443      0.000    -171.762    -130.716\n",
            "x24         -188.4253     13.048    -14.440      0.000    -214.000    -162.851\n",
            "x25           -0.5226      0.650     -0.805      0.421      -1.796       0.751\n",
            "x26           -0.6865      0.677     -1.014      0.311      -2.014       0.641\n",
            "x27           -0.0004      0.050     -0.008      0.994      -0.099       0.099\n",
            "x28            0.0948      0.056      1.690      0.091      -0.015       0.205\n",
            "x29           -0.1211      0.056     -2.176      0.030      -0.230      -0.012\n",
            "x30           -0.0266      0.049     -0.541      0.588      -0.123       0.070\n",
            "x31           -0.0711      0.061     -1.160      0.246      -0.191       0.049\n",
            "x32           -0.0040      0.052     -0.077      0.939      -0.107       0.099\n",
            "x33           -0.0518      0.052     -0.995      0.320      -0.154       0.050\n",
            "x34           -0.0605      0.054     -1.112      0.266      -0.167       0.046\n",
            "x35           -0.0208      0.055     -0.376      0.707      -0.129       0.088\n",
            "x36            0.1655      0.056      2.958      0.003       0.056       0.275\n",
            "x37           -0.0116      0.054     -0.215      0.830      -0.117       0.094\n",
            "x38           -0.0120      0.051     -0.234      0.815      -0.113       0.089\n",
            "x39            0.0296      0.055      0.541      0.589      -0.078       0.137\n",
            "x40           -0.0862      0.060     -1.437      0.151      -0.204       0.031\n",
            "x41           -0.0891      0.054     -1.644      0.100      -0.195       0.017\n",
            "x42           -0.0474      0.061     -0.782      0.434      -0.166       0.071\n",
            "x43            0.1019      0.048      2.141      0.032       0.009       0.195\n",
            "x44           -0.0501      0.064     -0.784      0.433      -0.176       0.075\n",
            "x45           -0.0608      0.064     -0.948      0.343      -0.186       0.065\n",
            "x46            0.0087      0.051      0.169      0.866      -0.092       0.109\n",
            "x47           -0.0665      0.055     -1.199      0.230      -0.175       0.042\n",
            "x48           -0.0242      0.058     -0.417      0.676      -0.138       0.090\n",
            "x49           -0.0700      0.053     -1.314      0.189      -0.174       0.034\n",
            "x50           -0.0117      0.054     -0.216      0.829      -0.118       0.094\n",
            "x51            0.0145      0.052      0.280      0.779      -0.087       0.116\n",
            "x52            0.0290      0.053      0.550      0.583      -0.074       0.132\n",
            "x53            0.0083      0.050      0.167      0.868      -0.090       0.106\n",
            "x54            0.0507      0.051      0.989      0.323      -0.050       0.151\n",
            "x55            0.0831      0.048      1.735      0.083      -0.011       0.177\n",
            "x56           -0.0035      0.051     -0.069      0.945      -0.103       0.096\n",
            "x57            0.0115      0.054      0.213      0.831      -0.094       0.118\n",
            "x58            0.0762      0.050      1.530      0.126      -0.021       0.174\n",
            "x59           -0.0980      0.055     -1.793      0.073      -0.205       0.009\n",
            "x60            0.0772      0.051      1.522      0.128      -0.022       0.177\n",
            "x61            0.0031      0.051      0.061      0.951      -0.097       0.103\n",
            "==============================================================================\n",
            "AIC: 2321.894436139116\n",
            "BIC: -2820.3850891825186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1838: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually create a dictionary to map row labels to more meaningful names\n",
        "row_mapping = {'const': 'Intercept'}\n",
        "for i, feature in enumerate(X.columns[1:], start=1):\n",
        "    row_mapping[f'x{i}'] = f'Coefficient for {feature}'\n",
        "\n",
        "# Display intermediate results for debugging\n",
        "print(\"Original Row Labels:\", X_train.columns.tolist())\n",
        "print(\"Row Mapping Dictionary:\", row_mapping)\n",
        "\n",
        "# Display the summary of the model\n",
        "summary_df_data = neg_binomial_model.summary().tables[1].data\n",
        "summary_df = pd.DataFrame(summary_df_data[1:], columns=summary_df_data[0])\n",
        "\n",
        "# Rename row labels using the row_mapping dictionary\n",
        "summary_df.index = [row_mapping.get(label, label) for label in summary_df.iloc[:, 0]]\n",
        "summary_df = summary_df.iloc[:, 1:]  # Remove the original label column\n",
        "\n",
        "# Display the final result\n",
        "display(summary_df)\n",
        "# Save the summary table as a CSV file\n",
        "summary_df.to_csv('neg_binomial_summary.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "wraMvi0a_GoX",
        "outputId": "5bf856d9-c809-4262-8936-c335e448bdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Row Labels: ['const', 'Word Count', 'Number of Hashtags', 'Colorfulness', 'No Image', 'Human Image', 'AI Image', 'AI art', 'Art Commission', 'Digital art', 'Discussion/Reflection', 'Meme', 'Miscellaneous', 'Non-digital art', 'Photograph', 'Promotion', 'Quote', 'Reply', 'Negative Sentiment', 'Neutral Sentiment', 'Positive Sentiment', 'Low Quality Image', 'High Quality Image', 'Irrelevant Image', 'Relevant Image', 'No Face Present', 'Face Present', 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'December', 'Hour_0', 'Hour_1', 'Hour_2', 'Hour_3', 'Hour_4', 'Hour_5', 'Hour_6', 'Hour_7', 'Hour_8', 'Hour_9', 'Hour_10', 'Hour_11', 'Hour_12', 'Hour_13', 'Hour_14', 'Hour_15', 'Hour_16', 'Hour_17', 'Hour_18', 'Hour_19', 'Hour_20', 'Hour_21', 'Hour_22', 'Hour_23']\n",
            "Row Mapping Dictionary: {'const': 'Intercept', 'x1': 'Coefficient for Word Count', 'x2': 'Coefficient for Number of Hashtags', 'x3': 'Coefficient for Colorfulness', 'x4': 'Coefficient for No Image', 'x5': 'Coefficient for Human Image', 'x6': 'Coefficient for AI Image', 'x7': 'Coefficient for AI art', 'x8': 'Coefficient for Art Commission', 'x9': 'Coefficient for Digital art', 'x10': 'Coefficient for Discussion/Reflection', 'x11': 'Coefficient for Meme', 'x12': 'Coefficient for Miscellaneous', 'x13': 'Coefficient for Non-digital art', 'x14': 'Coefficient for Photograph', 'x15': 'Coefficient for Promotion', 'x16': 'Coefficient for Quote', 'x17': 'Coefficient for Reply', 'x18': 'Coefficient for Negative Sentiment', 'x19': 'Coefficient for Neutral Sentiment', 'x20': 'Coefficient for Positive Sentiment', 'x21': 'Coefficient for Low Quality Image', 'x22': 'Coefficient for High Quality Image', 'x23': 'Coefficient for Irrelevant Image', 'x24': 'Coefficient for Relevant Image', 'x25': 'Coefficient for No Face Present', 'x26': 'Coefficient for Face Present', 'x27': 'Coefficient for January', 'x28': 'Coefficient for February', 'x29': 'Coefficient for March', 'x30': 'Coefficient for April', 'x31': 'Coefficient for May', 'x32': 'Coefficient for June', 'x33': 'Coefficient for July', 'x34': 'Coefficient for August', 'x35': 'Coefficient for September', 'x36': 'Coefficient for October', 'x37': 'Coefficient for December', 'x38': 'Coefficient for Hour_0', 'x39': 'Coefficient for Hour_1', 'x40': 'Coefficient for Hour_2', 'x41': 'Coefficient for Hour_3', 'x42': 'Coefficient for Hour_4', 'x43': 'Coefficient for Hour_5', 'x44': 'Coefficient for Hour_6', 'x45': 'Coefficient for Hour_7', 'x46': 'Coefficient for Hour_8', 'x47': 'Coefficient for Hour_9', 'x48': 'Coefficient for Hour_10', 'x49': 'Coefficient for Hour_11', 'x50': 'Coefficient for Hour_12', 'x51': 'Coefficient for Hour_13', 'x52': 'Coefficient for Hour_14', 'x53': 'Coefficient for Hour_15', 'x54': 'Coefficient for Hour_16', 'x55': 'Coefficient for Hour_17', 'x56': 'Coefficient for Hour_18', 'x57': 'Coefficient for Hour_19', 'x58': 'Coefficient for Hour_20', 'x59': 'Coefficient for Hour_21', 'x60': 'Coefficient for Hour_22', 'x61': 'Coefficient for Hour_23'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                          coef    std err          z   P>|z|  \\\n",
              "Intercept                            1.028e-12   7.06e-14     14.558   0.000   \n",
              "Coefficient for Word Count             -0.1504      0.066     -2.270   0.023   \n",
              "Coefficient for Number of Hashtags     -0.1245      0.085     -1.473   0.141   \n",
              "Coefficient for Colorfulness            0.0373      0.068      0.547   0.585   \n",
              "Coefficient for No Image               -0.0138      0.696     -0.020   0.984   \n",
              "...                                        ...        ...        ...     ...   \n",
              "Coefficient for Hour_19                 0.0115      0.054      0.213   0.831   \n",
              "Coefficient for Hour_20                 0.0762      0.050      1.530   0.126   \n",
              "Coefficient for Hour_21                -0.0980      0.055     -1.793   0.073   \n",
              "Coefficient for Hour_22                 0.0772      0.051      1.522   0.128   \n",
              "Coefficient for Hour_23                 0.0031      0.051      0.061   0.951   \n",
              "\n",
              "                                       [0.025     0.975]  \n",
              "Intercept                             8.9e-13   1.17e-12  \n",
              "Coefficient for Word Count             -0.280     -0.021  \n",
              "Coefficient for Number of Hashtags     -0.290      0.041  \n",
              "Coefficient for Colorfulness           -0.096      0.171  \n",
              "Coefficient for No Image               -1.378      1.350  \n",
              "...                                       ...        ...  \n",
              "Coefficient for Hour_19                -0.094      0.118  \n",
              "Coefficient for Hour_20                -0.021      0.174  \n",
              "Coefficient for Hour_21                -0.205      0.009  \n",
              "Coefficient for Hour_22                -0.022      0.177  \n",
              "Coefficient for Hour_23                -0.097      0.103  \n",
              "\n",
              "[62 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ceedf51c-7de3-4498-bb97-93fbff661de2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coef</th>\n",
              "      <th>std err</th>\n",
              "      <th>z</th>\n",
              "      <th>P&gt;|z|</th>\n",
              "      <th>[0.025</th>\n",
              "      <th>0.975]</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Intercept</th>\n",
              "      <td>1.028e-12</td>\n",
              "      <td>7.06e-14</td>\n",
              "      <td>14.558</td>\n",
              "      <td>0.000</td>\n",
              "      <td>8.9e-13</td>\n",
              "      <td>1.17e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coefficient for Word Count</th>\n",
              "      <td>-0.1504</td>\n",
              "      <td>0.066</td>\n",
              "      <td>-2.270</td>\n",
              "      <td>0.023</td>\n",
              "      <td>-0.280</td>\n",
              "      <td>-0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coefficient for Number of Hashtags</th>\n",
              "      <td>-0.1245</td>\n",
              "      <td>0.085</td>\n",
              "      <td>-1.473</td>\n",
              "      <td>0.141</td>\n",
              "      <td>-0.290</td>\n",
              "      <td>0.041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coefficient for Colorfulness</th>\n",
              "      <td>0.0373</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.547</td>\n",
              "      <td>0.585</td>\n",
              "      <td>-0.096</td>\n",
              "      <td>0.171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coefficient for No Image</th>\n",
              "      <td>-0.0138</td>\n",
              "      <td>0.696</td>\n",
              "      <td>-0.020</td>\n",
              "      <td>0.984</td>\n",
              "      <td>-1.378</td>\n",
              "      <td>1.350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coefficient for Hour_19</th>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.213</td>\n",
              "      <td>0.831</td>\n",
              "      <td>-0.094</td>\n",
              "      <td>0.118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coefficient for Hour_20</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.050</td>\n",
              "      <td>1.530</td>\n",
              "      <td>0.126</td>\n",
              "      <td>-0.021</td>\n",
              "      <td>0.174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coefficient for Hour_21</th>\n",
              "      <td>-0.0980</td>\n",
              "      <td>0.055</td>\n",
              "      <td>-1.793</td>\n",
              "      <td>0.073</td>\n",
              "      <td>-0.205</td>\n",
              "      <td>0.009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coefficient for Hour_22</th>\n",
              "      <td>0.0772</td>\n",
              "      <td>0.051</td>\n",
              "      <td>1.522</td>\n",
              "      <td>0.128</td>\n",
              "      <td>-0.022</td>\n",
              "      <td>0.177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coefficient for Hour_23</th>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0.951</td>\n",
              "      <td>-0.097</td>\n",
              "      <td>0.103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ceedf51c-7de3-4498-bb97-93fbff661de2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ceedf51c-7de3-4498-bb97-93fbff661de2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ceedf51c-7de3-4498-bb97-93fbff661de2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7418bc1-ff6a-4051-af1f-628e685dbf97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7418bc1-ff6a-4051-af1f-628e685dbf97')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7418bc1-ff6a-4051-af1f-628e685dbf97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Fqz7Jz1fd4",
        "outputId": "51557ac0-8870-438a-cc84-101abed08e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:       Engagement Score   No. Observations:                  560\n",
            "Model:                            GLM   Df Residuals:                      548\n",
            "Model Family:        NegativeBinomial   Df Model:                           11\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -1136.6\n",
            "Date:                Tue, 28 Nov 2023   Deviance:                       427.84\n",
            "Time:                        16:50:37   Pearson chi2:                     386.\n",
            "No. Iterations:                     8   Pseudo R-squ. (CS):            0.05657\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.8320      0.051     16.314      0.000       0.732       0.932\n",
            "x1            -0.1459      0.074     -1.975      0.048      -0.291      -0.001\n",
            "x2            -0.1523      0.067     -2.267      0.023      -0.284      -0.021\n",
            "x3             0.0931      0.052      1.794      0.073      -0.009       0.195\n",
            "x4            -0.1054      0.055     -1.928      0.054      -0.213       0.002\n",
            "x5            -0.1099      0.068     -1.604      0.109      -0.244       0.024\n",
            "x6             0.1400      0.062      2.264      0.024       0.019       0.261\n",
            "x7             0.0885      0.063      1.399      0.162      -0.036       0.213\n",
            "x8            -0.1378      0.057     -2.416      0.016      -0.250      -0.026\n",
            "x9             0.0513      0.057      0.899      0.369      -0.061       0.163\n",
            "x10            0.0865      0.060      1.448      0.147      -0.031       0.204\n",
            "x11            0.0692      0.054      1.288      0.198      -0.036       0.175\n",
            "==============================================================================\n",
            "AIC: 2297.1696023585405\n",
            "BIC: -3039.8670782309077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1838: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import resample  # Import resample for random sampling\n",
        "\n",
        "# Load your dataset (replace 'All_Tweets_Transformed-Final.csv' with your actual file path)\n",
        "df = pd.read_csv('All_Tweets_Transformed-Final.csv')\n",
        "\n",
        "# Drop rows with NaN values in the target variable\n",
        "df_regression = df.dropna(subset=['Engagement Score'])\n",
        "\n",
        "# Extract month and hour from the timestamp\n",
        "df_regression['Timestamp'] = pd.to_datetime(df_regression['Timestamp'])\n",
        "df_regression['Month'] = df_regression['Timestamp'].dt.month\n",
        "df_regression['Hour'] = df_regression['Timestamp'].dt.hour\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['Image Type', 'Topic', 'Text Sentiment', 'Word Count', 'Number of Hashtags', 'Quality of Image', 'Relevant Image', 'Face Presence', 'Colorfulness', 'Month', 'Hour']\n",
        "target = 'Engagement Score'\n",
        "\n",
        "# Use LabelEncoder for the 'Topic' variable\n",
        "label_encoder = LabelEncoder()\n",
        "df_regression['Topic'] = label_encoder.fit_transform(df_regression['Topic'])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df_regression[features]\n",
        "y = df_regression[target]\n",
        "\n",
        "# Take a random sample of 700\n",
        "df_sample = resample(df_regression, n_samples=700, random_state=42)\n",
        "\n",
        "# Separate features and target variable for the sample\n",
        "X_sample = df_sample[features]\n",
        "y_sample = df_sample[target]\n",
        "\n",
        "# Split the data into training and testing sets for the sample\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Add a constant term to the features matrix\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "# Fit a Negative Binomial regression model\n",
        "neg_binomial_model = sm.GLM(y_train, sm.add_constant(X_train_scaled), family=sm.families.NegativeBinomial()).fit()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = neg_binomial_model.predict(sm.add_constant(X_test_scaled))\n",
        "\n",
        "# Display the summary of the model\n",
        "print(neg_binomial_model.summary())\n",
        "\n",
        "# Calculate AIC and BIC\n",
        "aic = neg_binomial_model.aic\n",
        "bic = neg_binomial_model.bic\n",
        "\n",
        "print(f'AIC: {aic}')\n",
        "print(f'BIC: {bic}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 1**\n",
        "All features"
      ],
      "metadata": {
        "id": "kO_aLx_51kFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 2**\n",
        "Without time features"
      ],
      "metadata": {
        "id": "ip3NVwCJ1-0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import resample  # Import resample for random sampling\n",
        "\n",
        "# Load your dataset (replace 'All_Tweets_Transformed-Final.csv' with your actual file path)\n",
        "df = pd.read_csv('All_Tweets_Transformed-Final.csv')\n",
        "\n",
        "# Drop rows with NaN values in the target variable\n",
        "df_regression = df.dropna(subset=['Engagement Score'])\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['Image Type', 'Topic', 'Text Sentiment', 'Word Count', 'Number of Hashtags', 'Quality of Image', 'Relevant Image', 'Face Presence', 'Colorfulness']\n",
        "target = 'Engagement Score'\n",
        "\n",
        "# Use LabelEncoder for the 'Topic' variable\n",
        "label_encoder = LabelEncoder()\n",
        "df_regression['Topic'] = label_encoder.fit_transform(df_regression['Topic'])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df_regression[features]\n",
        "y = df_regression[target]\n",
        "\n",
        "# Take a random sample of 700\n",
        "df_sample = resample(df_regression, n_samples=700, random_state=42)\n",
        "\n",
        "# Separate features and target variable for the sample\n",
        "X_sample = df_sample[features]\n",
        "y_sample = df_sample[target]\n",
        "\n",
        "# Split the data into training and testing sets for the sample\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Add a constant term to the features matrix\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "# Fit a Negative Binomial regression model\n",
        "neg_binomial_model = sm.GLM(y_train, sm.add_constant(X_train_scaled), family=sm.families.NegativeBinomial()).fit()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = neg_binomial_model.predict(sm.add_constant(X_test_scaled))\n",
        "\n",
        "# Display the summary of the model\n",
        "print(neg_binomial_model.summary())\n",
        "\n",
        "# Calculate AIC and BIC\n",
        "aic = neg_binomial_model.aic\n",
        "bic = neg_binomial_model.bic\n",
        "\n",
        "print(f'AIC: {aic}')\n",
        "print(f'BIC: {bic}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjY1gxq11-XA",
        "outputId": "57cf9be3-ff22-42de-e7f3-3829872188c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:       Engagement Score   No. Observations:                  560\n",
            "Model:                            GLM   Df Residuals:                      550\n",
            "Model Family:        NegativeBinomial   Df Model:                            9\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -1138.2\n",
            "Date:                Tue, 28 Nov 2023   Deviance:                       431.04\n",
            "Time:                        17:04:15   Pearson chi2:                     381.\n",
            "No. Iterations:                     8   Pseudo R-squ. (CS):            0.05118\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.8359      0.051     16.414      0.000       0.736       0.936\n",
            "x1            -0.1661      0.071     -2.333      0.020      -0.306      -0.027\n",
            "x2            -0.1252      0.066     -1.898      0.058      -0.254       0.004\n",
            "x3             0.0831      0.052      1.614      0.107      -0.018       0.184\n",
            "x4            -0.0977      0.054     -1.794      0.073      -0.204       0.009\n",
            "x5            -0.1335      0.067     -2.008      0.045      -0.264      -0.003\n",
            "x6             0.1366      0.062      2.213      0.027       0.016       0.258\n",
            "x7             0.0949      0.063      1.505      0.132      -0.029       0.219\n",
            "x8            -0.1463      0.056     -2.596      0.009      -0.257      -0.036\n",
            "x9             0.0597      0.057      1.051      0.293      -0.052       0.171\n",
            "==============================================================================\n",
            "AIC: 2296.3641249769225\n",
            "BIC: -3049.3284291799846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1838: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 3**\n",
        "Greater importance to image features"
      ],
      "metadata": {
        "id": "jd6Oi0Z15rxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import resample  # Import resample for random sampling\n",
        "\n",
        "# Load your dataset (replace 'All_Tweets_Transformed-Final.csv' with your actual file path)\n",
        "df = pd.read_csv('All_Tweets_Transformed-Final.csv')\n",
        "\n",
        "# Drop rows with NaN values in the target variable\n",
        "df_regression = df.dropna(subset=['Engagement Score'])\n",
        "\n",
        "# Extract month and hour from the timestamp\n",
        "df_regression['Timestamp'] = pd.to_datetime(df_regression['Timestamp'])\n",
        "df_regression['Month'] = df_regression['Timestamp'].dt.month\n",
        "df_regression['Hour'] = df_regression['Timestamp'].dt.hour\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['Image Type', 'Topic', 'Text Sentiment', 'Word Count', 'Number of Hashtags', 'Quality of Image', 'Relevant Image', 'Face Presence', 'Colorfulness', 'Month', 'Hour']\n",
        "target = 'Engagement Score'\n",
        "\n",
        "# Use LabelEncoder for the 'Topic' variable\n",
        "label_encoder = LabelEncoder()\n",
        "df_regression['Topic'] = label_encoder.fit_transform(df_regression['Topic'])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df_regression[features]\n",
        "y = df_regression[target]\n",
        "\n",
        "# Take a random sample of 700\n",
        "df_sample = resample(df_regression, n_samples=700, random_state=42)\n",
        "\n",
        "# Separate features and target variable for the sample\n",
        "X_sample = df_sample[features]\n",
        "y_sample = df_sample[target]\n",
        "\n",
        "# Split the data into training and testing sets for the sample\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Add a constant term to the features matrix\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "# Assign weights to training data\n",
        "weights_train = [1] * len(X_train)  # default weight for observations not related to image features\n",
        "image_features = ['Image Type', 'Quality of Image', 'Relevant Image', 'Face Presence', 'Colorfulness']\n",
        "weights_train = [2 if idx in X_train.index[X_train.index.isin(image_features)] else 1 for idx in X_train.index]\n",
        "\n",
        "# Fit a Negative Binomial regression model with weights\n",
        "neg_binomial_model = sm.GLM(y_train, sm.add_constant(X_train_scaled), family=sm.families.NegativeBinomial(), freq_weights=weights_train).fit()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = neg_binomial_model.predict(sm.add_constant(X_test_scaled))\n",
        "\n",
        "# Display the summary of the model\n",
        "print(neg_binomial_model.summary())\n",
        "\n",
        "# Calculate AIC and BIC\n",
        "aic = neg_binomial_model.aic\n",
        "bic = neg_binomial_model.bic\n",
        "\n",
        "print(f'AIC: {aic}')\n",
        "print(f'BIC: {bic}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1SD-qhn5AZJ",
        "outputId": "81e4c618-89c2-48b7-88e9-9d4d9e1828cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:       Engagement Score   No. Observations:                  560\n",
            "Model:                            GLM   Df Residuals:                      548\n",
            "Model Family:        NegativeBinomial   Df Model:                           11\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -1136.6\n",
            "Date:                Tue, 28 Nov 2023   Deviance:                       427.84\n",
            "Time:                        17:14:07   Pearson chi2:                     386.\n",
            "No. Iterations:                     8   Pseudo R-squ. (CS):            0.05657\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.8320      0.051     16.314      0.000       0.732       0.932\n",
            "x1            -0.1459      0.074     -1.975      0.048      -0.291      -0.001\n",
            "x2            -0.1523      0.067     -2.267      0.023      -0.284      -0.021\n",
            "x3             0.0931      0.052      1.794      0.073      -0.009       0.195\n",
            "x4            -0.1054      0.055     -1.928      0.054      -0.213       0.002\n",
            "x5            -0.1099      0.068     -1.604      0.109      -0.244       0.024\n",
            "x6             0.1400      0.062      2.264      0.024       0.019       0.261\n",
            "x7             0.0885      0.063      1.399      0.162      -0.036       0.213\n",
            "x8            -0.1378      0.057     -2.416      0.016      -0.250      -0.026\n",
            "x9             0.0513      0.057      0.899      0.369      -0.061       0.163\n",
            "x10            0.0865      0.060      1.448      0.147      -0.031       0.204\n",
            "x11            0.0692      0.054      1.288      0.198      -0.036       0.175\n",
            "==============================================================================\n",
            "AIC: 2297.1696023585405\n",
            "BIC: -3039.8670782309077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1838: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 4**\n",
        "\n",
        "Greater weight to text characteristics"
      ],
      "metadata": {
        "id": "t82cQeF5_LUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import resample  # Import resample for random sampling\n",
        "\n",
        "# Load your dataset (replace 'All_Tweets_Transformed-Final.csv' with your actual file path)\n",
        "df = pd.read_csv('All_Tweets_Transformed-Final.csv')\n",
        "\n",
        "# Drop rows with NaN values in the target variable\n",
        "df_regression = df.dropna(subset=['Engagement Score'])\n",
        "\n",
        "# Extract month and hour from the timestamp\n",
        "df_regression['Timestamp'] = pd.to_datetime(df_regression['Timestamp'])\n",
        "df_regression['Month'] = df_regression['Timestamp'].dt.month\n",
        "df_regression['Hour'] = df_regression['Timestamp'].dt.hour\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['Image Type', 'Topic', 'Text Sentiment', 'Word Count', 'Number of Hashtags', 'Quality of Image', 'Relevant Image', 'Face Presence', 'Colorfulness', 'Month', 'Hour']\n",
        "target = 'Engagement Score'\n",
        "\n",
        "# Use LabelEncoder for the 'Topic' variable\n",
        "label_encoder = LabelEncoder()\n",
        "df_regression['Topic'] = label_encoder.fit_transform(df_regression['Topic'])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df_regression[features]\n",
        "y = df_regression[target]\n",
        "\n",
        "# Take a random sample of 700\n",
        "df_sample = resample(df_regression, n_samples=700, random_state=42)\n",
        "\n",
        "# Separate features and target variable for the sample\n",
        "X_sample = df_sample[features]\n",
        "y_sample = df_sample[target]\n",
        "\n",
        "# Split the data into training and testing sets for the sample\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Add a constant term to the features matrix\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "# Assign weights to training data\n",
        "weights_train = [1] * len(X_train)  # default weight for observations not related to text features\n",
        "text_features = ['Text Sentiment', 'Word Count', 'Number of Hashtags']\n",
        "weights_train = [2 if idx in X_train.index[X_train.index.isin(text_features)] else 1 for idx in X_train.index]\n",
        "\n",
        "# Fit a Negative Binomial regression model with weights\n",
        "neg_binomial_model = sm.GLM(y_train, sm.add_constant(X_train_scaled), family=sm.families.NegativeBinomial(), freq_weights=weights_train).fit()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred_test = neg_binomial_model.predict(sm.add_constant(X_test_scaled))\n",
        "\n",
        "# Display the summary of the model\n",
        "print(neg_binomial_model.summary())\n",
        "\n",
        "# Calculate AIC and BIC\n",
        "aic = neg_binomial_model.aic\n",
        "bic = neg_binomial_model.bic\n",
        "\n",
        "print(f'AIC: {aic}')\n",
        "print(f'BIC: {bic}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4bllj5g_Qat",
        "outputId": "31c50be6-25e1-4dc3-f1d5-4dadc7d531f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:       Engagement Score   No. Observations:                  560\n",
            "Model:                            GLM   Df Residuals:                      548\n",
            "Model Family:        NegativeBinomial   Df Model:                           11\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -1136.6\n",
            "Date:                Tue, 28 Nov 2023   Deviance:                       427.84\n",
            "Time:                        17:34:19   Pearson chi2:                     386.\n",
            "No. Iterations:                     8   Pseudo R-squ. (CS):            0.05657\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.8320      0.051     16.314      0.000       0.732       0.932\n",
            "x1            -0.1459      0.074     -1.975      0.048      -0.291      -0.001\n",
            "x2            -0.1523      0.067     -2.267      0.023      -0.284      -0.021\n",
            "x3             0.0931      0.052      1.794      0.073      -0.009       0.195\n",
            "x4            -0.1054      0.055     -1.928      0.054      -0.213       0.002\n",
            "x5            -0.1099      0.068     -1.604      0.109      -0.244       0.024\n",
            "x6             0.1400      0.062      2.264      0.024       0.019       0.261\n",
            "x7             0.0885      0.063      1.399      0.162      -0.036       0.213\n",
            "x8            -0.1378      0.057     -2.416      0.016      -0.250      -0.026\n",
            "x9             0.0513      0.057      0.899      0.369      -0.061       0.163\n",
            "x10            0.0865      0.060      1.448      0.147      -0.031       0.204\n",
            "x11            0.0692      0.054      1.288      0.198      -0.036       0.175\n",
            "==============================================================================\n",
            "AIC: 2297.1696023585405\n",
            "BIC: -3039.8670782309077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1838: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 5**\n",
        "\n",
        "No Image Characteristics"
      ],
      "metadata": {
        "id": "DjwEXljOBHyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import resample  # Import resample for random sampling\n",
        "\n",
        "# Load your dataset (replace 'All_Tweets_Transformed-Final.csv' with your actual file path)\n",
        "df = pd.read_csv('All_Tweets_Transformed-Final.csv')\n",
        "\n",
        "# Drop rows with NaN values in the target variable\n",
        "df_regression = df.dropna(subset=['Engagement Score'])\n",
        "\n",
        "# Extract month and hour from the timestamp\n",
        "df_regression['Timestamp'] = pd.to_datetime(df_regression['Timestamp'])\n",
        "df_regression['Month'] = df_regression['Timestamp'].dt.month\n",
        "df_regression['Hour'] = df_regression['Timestamp'].dt.hour\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['Topic', 'Text Sentiment', 'Word Count', 'Number of Hashtags', 'Month', 'Hour']\n",
        "target = 'Engagement Score'\n",
        "\n",
        "# Use LabelEncoder for the 'Topic' variable\n",
        "label_encoder = LabelEncoder()\n",
        "df_regression['Topic'] = label_encoder.fit_transform(df_regression['Topic'])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df_regression[features]\n",
        "y = df_regression[target]\n",
        "\n",
        "# Take a random sample of 700\n",
        "df_sample = resample(df_regression, n_samples=700, random_state=42)\n",
        "\n",
        "# Separate features and target variable for the sample\n",
        "X_sample = df_sample[features]\n",
        "y_sample = df_sample[target]\n",
        "\n",
        "# Split the data into training and testing sets for the sample\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Add a constant term to the features matrix\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "# Fit a Negative Binomial regression model\n",
        "neg_binomial_model = sm.GLM(y_train, sm.add_constant(X_train_scaled), family=sm.families.NegativeBinomial()).fit()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = neg_binomial_model.predict(sm.add_constant(X_test_scaled))\n",
        "\n",
        "# Display the summary of the model\n",
        "print(neg_binomial_model.summary())\n",
        "\n",
        "# Calculate AIC and BIC\n",
        "aic = neg_binomial_model.aic\n",
        "bic = neg_binomial_model.bic\n",
        "\n",
        "print(f'AIC: {aic}')\n",
        "print(f'BIC: {bic}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rW4YY1oBHX-",
        "outputId": "8d057089-ca5e-4d3f-ee4f-8a3260845065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:       Engagement Score   No. Observations:                  560\n",
            "Model:                            GLM   Df Residuals:                      553\n",
            "Model Family:        NegativeBinomial   Df Model:                            6\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -1144.3\n",
            "Date:                Tue, 28 Nov 2023   Deviance:                       443.25\n",
            "Time:                        17:41:26   Pearson chi2:                     397.\n",
            "No. Iterations:                     7   Pseudo R-squ. (CS):            0.03026\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.8523      0.051     16.823      0.000       0.753       0.952\n",
            "x1            -0.0838      0.057     -1.476      0.140      -0.195       0.027\n",
            "x2             0.1048      0.051      2.071      0.038       0.006       0.204\n",
            "x3            -0.0887      0.054     -1.650      0.099      -0.194       0.017\n",
            "x4            -0.1470      0.058     -2.546      0.011      -0.260      -0.034\n",
            "x5             0.1045      0.057      1.827      0.068      -0.008       0.217\n",
            "x6             0.0856      0.053      1.622      0.105      -0.018       0.189\n",
            "==============================================================================\n",
            "AIC: 2302.575193460726\n",
            "BIC: -3056.1011710473686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1838: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model 6**\n",
        "\n",
        "No Text Characteristics"
      ],
      "metadata": {
        "id": "5BgPJWWIBrQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import resample  # Import resample for random sampling\n",
        "\n",
        "# Load your dataset (replace 'All_Tweets_Transformed-Final.csv' with your actual file path)\n",
        "df = pd.read_csv('All_Tweets_Transformed-Final.csv')\n",
        "\n",
        "# Drop rows with NaN values in the target variable\n",
        "df_regression = df.dropna(subset=['Engagement Score'])\n",
        "\n",
        "# Extract month and hour from the timestamp\n",
        "df_regression['Timestamp'] = pd.to_datetime(df_regression['Timestamp'])\n",
        "df_regression['Month'] = df_regression['Timestamp'].dt.month\n",
        "df_regression['Hour'] = df_regression['Timestamp'].dt.hour\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['Image Type', 'Topic', 'Quality of Image', 'Relevant Image', 'Face Presence', 'Colorfulness', 'Month', 'Hour']\n",
        "target = 'Engagement Score'\n",
        "\n",
        "# Use LabelEncoder for the 'Topic' variable\n",
        "label_encoder = LabelEncoder()\n",
        "df_regression['Topic'] = label_encoder.fit_transform(df_regression['Topic'])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df_regression[features]\n",
        "y = df_regression[target]\n",
        "\n",
        "# Take a random sample of 700\n",
        "df_sample = resample(df_regression, n_samples=700, random_state=42)\n",
        "\n",
        "# Separate features and target variable for the sample\n",
        "X_sample = df_sample[features]\n",
        "y_sample = df_sample[target]\n",
        "\n",
        "# Split the data into training and testing sets for the sample\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "# Add a constant term to the features matrix\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "# Fit a Negative Binomial regression model\n",
        "neg_binomial_model = sm.GLM(y_train, sm.add_constant(X_train_scaled), family=sm.families.NegativeBinomial()).fit()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = neg_binomial_model.predict(sm.add_constant(X_test_scaled))\n",
        "\n",
        "# Display the summary of the model\n",
        "print(neg_binomial_model.summary())\n",
        "\n",
        "# Calculate AIC and BIC\n",
        "aic = neg_binomial_model.aic\n",
        "bic = neg_binomial_model.bic\n",
        "\n",
        "print(f'AIC: {aic}')\n",
        "print(f'BIC: {bic}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shxiT_fZBqiu",
        "outputId": "f6cb6051-a1e8-4957-fa68-44f14c3dbb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:       Engagement Score   No. Observations:                  560\n",
            "Model:                            GLM   Df Residuals:                      551\n",
            "Model Family:        NegativeBinomial   Df Model:                            8\n",
            "Link Function:                    Log   Scale:                          1.0000\n",
            "Method:                          IRLS   Log-Likelihood:                -1139.9\n",
            "Date:                Tue, 28 Nov 2023   Deviance:                       434.52\n",
            "Time:                        17:47:35   Pearson chi2:                     400.\n",
            "No. Iterations:                     7   Pseudo R-squ. (CS):            0.04526\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.8405      0.051     16.525      0.000       0.741       0.940\n",
            "x1            -0.1870      0.073     -2.569      0.010      -0.330      -0.044\n",
            "x2            -0.1525      0.066     -2.294      0.022      -0.283      -0.022\n",
            "x3             0.1678      0.061      2.755      0.006       0.048       0.287\n",
            "x4             0.0976      0.061      1.602      0.109      -0.022       0.217\n",
            "x5            -0.1021      0.055     -1.853      0.064      -0.210       0.006\n",
            "x6             0.0425      0.056      0.753      0.452      -0.068       0.153\n",
            "x7             0.0868      0.058      1.491      0.136      -0.027       0.201\n",
            "x8             0.0622      0.053      1.179      0.239      -0.041       0.165\n",
            "==============================================================================\n",
            "AIC: 2297.8478054204174\n",
            "BIC: -3052.172685520219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
            "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n",
            "/usr/local/lib/python3.10/dist-packages/statsmodels/genmod/generalized_linear_model.py:1838: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}